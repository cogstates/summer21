{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import operator\n",
    "import itertools\n",
    "import random\n",
    "from itertools import islice\n",
    "from functools import reduce\n",
    "\n",
    "import nlpaug.augmenter.word as naw\n",
    "from datasets import Dataset, DatasetDict, ClassLabel\n",
    "\n",
    "from jadoch.data import costep\n",
    "from jadoch.data.costep import language, contains, starts_with, some\n",
    "from jadoch.core.functional import ilen, save_iter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "german = language(\"german\")\n",
    "english = language(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hopefully this ensures it's the correct \"ja\".\n",
    "ignores = map(\n",
    "    contains,\n",
    "    [\n",
    "        \"sagt ja\",\n",
    "        \"sagen ja\",\n",
    "        \"sage ja\",\n",
    "        \"sagten ja\",\n",
    "        \"sagte ja\",\n",
    "        \"ja oder\",\n",
    "        \"ja zum\" ,\n",
    "        \"ja zur\",\n",
    "        \"ja zu\"\n",
    "    ]\n",
    ")\n",
    "fltr = german(contains(\"ja\") & ~starts_with(\"ja\") & ~some(*ignores)) & english(~contains(\"yes\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelify(label):\n",
    "    def func(val):\n",
    "        return (val, label)\n",
    "    return func\n",
    "\n",
    "\n",
    "def mapify(functions, iterable):\n",
    "    fns = iter(functions)\n",
    "    for fn in fns:\n",
    "        iterable = map(fn, iterable)\n",
    "    return iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(fltr, label, fn=lambda v: v):\n",
    "    return mapify(\n",
    "        (\n",
    "            operator.itemgetter(\"english\"),\n",
    "            fn,\n",
    "            labelify(label)\n",
    "        ),\n",
    "        filter(\n",
    "            fltr, \n",
    "            costep.sentences(\"english\", \"german\")\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('After all, we have in you an expert who is in any case closely concerned with these matters.',\n",
       "  'ja'),\n",
       " ('I declare resumed the session of the European Parliament adjourned on Thursday, 28 March 1996.',\n",
       "  'na'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(search(fltr, \"ja\")), next(search(~fltr, \"na\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentify(model_path=\"distilbert-base-uncased\", action=\"substitute\"):\n",
    "    ctx = naw.ContextualWordEmbsAug(model_path=model_path, action=action)\n",
    "    def func(txt):\n",
    "        return ctx.augment(txt)\n",
    "    return func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('After all, we have in you an expert who is in any case closely concerned with these matters.',\n",
       "  'ja'),\n",
       " ('after all, we must paid you an expert who assisting in the case severely concerned with these matters.',\n",
       "  'ja'))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(search(fltr, \"ja\")), next(search(fltr, \"ja\", augmentify()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generation\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(itr, pct):\n",
    "    items = list(itr)\n",
    "    idx = round(len(items) * pct)\n",
    "    return items[:idx], items[idx:]\n",
    "\n",
    "\n",
    "def partition(iterable, sizes):\n",
    "    it = iter(iterable)\n",
    "\n",
    "    for size in sizes:\n",
    "        if size is None:\n",
    "            yield list(it)\n",
    "            return\n",
    "        else:\n",
    "            yield list(islice(it, size))\n",
    "\n",
    "\n",
    "def generate(fltr, limit):    \n",
    "    # jas = search(fltr, \"ja\")\n",
    "    jas = itertools.chain(*[search(fltr, \"ja\")] + [search(fltr, \"ja\", augmentify()) for _ in range(10)])\n",
    "    nas = search(~fltr, \"na\")\n",
    "    train_jas, test_jas = split(islice(jas, limit), 0.8)\n",
    "    train_nas, test_nas = split(islice(nas, limit), 0.8)\n",
    "    # train_nas, test_nas = partition(nas, [len(train_jas), None])\n",
    "    training_data = train_jas + train_nas\n",
    "    testing_data = test_jas + test_nas\n",
    "    random.shuffle(training_data)\n",
    "    random.shuffle(testing_data)\n",
    "    class_label = ClassLabel(num_classes=2, names=[\"na\", \"ja\"]) # XXX: ???\n",
    "    reshape = lambda dt: {\n",
    "        \"text\": [tup[0] for tup in dt],\n",
    "        \"label\": list(map(class_label.str2int, [tup[1] for tup in dt]))\n",
    "    }\n",
    "    return DatasetDict({\n",
    "        \"train\": Dataset.from_dict(reshape(training_data)),\n",
    "        \"test\": Dataset.from_dict(reshape(testing_data))\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = generate(fltr, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data#.save_to_disk(\"/gpfs/scratch/asoubki/data/english-balanced-train-test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
